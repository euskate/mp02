{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import mglearn\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>avg_moo</th>\n",
       "      <th>avgY_moo</th>\n",
       "      <th>현재기온</th>\n",
       "      <th>이슬점온도</th>\n",
       "      <th>체감온도</th>\n",
       "      <th>습도</th>\n",
       "      <th>풍속</th>\n",
       "      <th>해면기압</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1092</td>\n",
       "      <td>1334</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-9.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1007.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1129</td>\n",
       "      <td>1314</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>-22.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>1019.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1151</td>\n",
       "      <td>1287</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1162</td>\n",
       "      <td>1275</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1022.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1112</td>\n",
       "      <td>1255</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1020.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2671</td>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>3073</td>\n",
       "      <td>1618</td>\n",
       "      <td>10.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1025.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2672</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>3068</td>\n",
       "      <td>1596</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1012.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2673</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>3022</td>\n",
       "      <td>1582</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1022.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2674</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2987</td>\n",
       "      <td>1480</td>\n",
       "      <td>13.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1019.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>3023</td>\n",
       "      <td>1473</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1031.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              날짜  avg_moo  avgY_moo  현재기온  이슬점온도  체감온도    습도    풍속    해면기압\n",
       "0     2010-01-04     1092      1334  -6.0   -7.3  -9.6  90.0   7.6  1007.7\n",
       "1     2010-01-05     1129      1314 -11.7  -16.2 -22.3  69.0  33.8  1019.2\n",
       "2     2010-01-06     1151      1287 -10.6  -17.6 -16.0  56.0  10.1  1021.5\n",
       "3     2010-01-07     1162      1275  -6.1  -13.9  -6.1  54.0   1.8  1022.8\n",
       "4     2010-01-08     1112      1255  -3.8  -11.7  -8.2  54.0  11.2  1020.1\n",
       "...          ...      ...       ...   ...    ...   ...   ...   ...     ...\n",
       "2671  2019-12-24     3073      1618  10.9   -0.5   9.2  45.0  13.3  1025.4\n",
       "2672  2019-12-26     3068      1596   6.1    0.6   3.0  68.0  15.8  1012.9\n",
       "2673  2019-12-27     3022      1582   8.1  -12.3   5.4  22.0  16.2  1022.1\n",
       "2674  2019-12-30     2987      1480  13.3    7.5  12.5  68.0  10.4  1019.7\n",
       "2675  2019-12-31     3023      1473   2.5  -18.2  -1.9  20.0  18.7  1031.1\n",
       "\n",
       "[2676 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/maindata_moo.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['날짜']\n",
    "del data['avg_moo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "# data.isnull().sum()\n",
    "\n",
    "# 결측치 처리\n",
    "data.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdy = data.iloc[:, 0]\n",
    "pdx = data.iloc[:, 1:]\n",
    "x_train,x_test,y_train,y_test=train_test_split(pdx,pdy,train_size=0.3, random_state = 42)\n",
    "x_train_new = sm.add_constant(x_train)\n",
    "x_test_new = sm.add_constant(x_test)\n",
    "full_mod = sm.OLS(y_train,x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               avgY_moo   R-squared:                       0.487\n",
      "Model:                            OLS   Adj. R-squared:                  0.483\n",
      "Method:                 Least Squares   F-statistic:                     125.8\n",
      "Date:                Wed, 19 Feb 2020   Prob (F-statistic):          1.07e-111\n",
      "Time:                        13:50:29   Log-Likelihood:                -5490.4\n",
      "No. Observations:                 802   AIC:                         1.099e+04\n",
      "Df Residuals:                     795   BIC:                         1.103e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2671.2852   1775.220     -1.505      0.133   -6155.957     813.387\n",
      "현재기온          24.0761      5.723      4.207      0.000      12.842      35.310\n",
      "이슬점온도         10.8910      5.529      1.970      0.049       0.038      21.744\n",
      "체감온도          -4.0153      0.612     -6.564      0.000      -5.216      -2.815\n",
      "습도            -1.1755      1.748     -0.672      0.502      -4.607       2.256\n",
      "풍속            -2.1506      1.513     -1.422      0.156      -5.120       0.819\n",
      "해면기압           3.9835      1.705      2.337      0.020       0.637       7.330\n",
      "==============================================================================\n",
      "Omnibus:                       36.487   Durbin-Watson:                   2.080\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.699\n",
      "Skew:                           0.547   Prob(JB):                     1.45e-09\n",
      "Kurtosis:                       2.862   Cond. No.                     2.24e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.24e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " Variance Inflation Factor\n",
      "현재기온 45.588\n",
      "이슬점온도 74.068\n",
      "체감온도 6.141\n",
      "습도 21.868\n",
      "풍속 1.302\n",
      "해면기압 2.594\n"
     ]
    }
   ],
   "source": [
    "# 독립변수의 R제곱, P값까지 포함한 모델 요약 출력\n",
    "full_res = full_mod.fit()\n",
    "print('\\n \\n', full_res.summary())\n",
    "\n",
    "# 각 개별 변수의 VIF를 계산\n",
    "# 각 변수의 R제곱값을 계산, VIF 값으로 변환\n",
    "print('\\n Variance Inflation Factor')\n",
    "cnames = x_train.columns\n",
    "for i in np.arange(0,len(cnames)):\n",
    "    xvars = list(cnames)\n",
    "    yvars = xvars.pop(i)\n",
    "    mod = sm.OLS(x_train[yvars], sm.add_constant( x_train_new[xvars]))\n",
    "    res = mod.fit()\n",
    "    vif = 1/(1-res.rsquared)\n",
    "    print(yvars, round(vif, 3))\n",
    "    \n",
    "\n",
    "# AIS \n",
    "# = 1.099e+04\n",
    "# 수정 R제곱\n",
    "# = 0.483\n",
    "# 개별변수의 P값 ( P > |t|)\n",
    "# = 0.502, 습도 삭제처리\n",
    "# 개별변수의 VIF값\n",
    "# = 74.068, 이슬점온도 삭제처리\n",
    "\n",
    "# 이슬점온도 먼저 삭제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['이슬점온도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdy = data.iloc[:, 0]\n",
    "pdx = data.iloc[:, 1:]\n",
    "x_train,x_test,y_train,y_test=train_test_split(pdx,pdy,train_size=0.3, random_state = 42)\n",
    "x_train_new = sm.add_constant(x_train)\n",
    "x_test_new = sm.add_constant(x_test)\n",
    "full_mod = sm.OLS(y_train,x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               avgY_moo   R-squared:                       0.485\n",
      "Model:                            OLS   Adj. R-squared:                  0.481\n",
      "Method:                 Least Squares   F-statistic:                     149.7\n",
      "Date:                Wed, 19 Feb 2020   Prob (F-statistic):          5.69e-112\n",
      "Time:                        13:50:29   Log-Likelihood:                -5492.3\n",
      "No. Observations:                 802   AIC:                         1.100e+04\n",
      "Df Residuals:                     796   BIC:                         1.102e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -3227.1864   1755.811     -1.838      0.066   -6673.754     219.381\n",
      "현재기온          34.6988      1.919     18.085      0.000      30.933      38.465\n",
      "체감온도          -4.0597      0.612     -6.629      0.000      -5.262      -2.858\n",
      "습도             2.1405      0.472      4.531      0.000       1.213       3.068\n",
      "풍속            -1.7924      1.505     -1.191      0.234      -4.746       1.161\n",
      "해면기압           4.2430      1.703      2.492      0.013       0.901       7.585\n",
      "==============================================================================\n",
      "Omnibus:                       33.065   Durbin-Watson:                   2.071\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.364\n",
      "Skew:                           0.515   Prob(JB):                     1.27e-08\n",
      "Kurtosis:                       2.838   Cond. No.                     2.21e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.21e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " Variance Inflation Factor\n",
      "현재기온 5.105\n",
      "체감온도 6.133\n",
      "습도 1.591\n",
      "풍속 1.283\n",
      "해면기압 2.578\n"
     ]
    }
   ],
   "source": [
    "# 독립변수의 R제곱, P값까지 포함한 모델 요약 출력\n",
    "full_res = full_mod.fit()\n",
    "print('\\n \\n', full_res.summary())\n",
    "\n",
    "# 각 개별 변수의 VIF를 계산\n",
    "# 각 변수의 R제곱값을 계산, VIF 값으로 변환\n",
    "print('\\n Variance Inflation Factor')\n",
    "cnames = x_train.columns\n",
    "for i in np.arange(0,len(cnames)):\n",
    "    xvars = list(cnames)\n",
    "    yvars = xvars.pop(i)\n",
    "    mod = sm.OLS(x_train[yvars], sm.add_constant( x_train_new[xvars]))\n",
    "    res = mod.fit()\n",
    "    vif = 1/(1-res.rsquared)\n",
    "    print(yvars, round(vif, 3))\n",
    "    \n",
    "\n",
    "# AIS \n",
    "# = 1.099e+04 -> 1.100e+04\n",
    "# 수정 R제곱\n",
    "# = 0.483 -> 0.481\n",
    "# 개별변수의 P값 ( P > |t|)\n",
    "# = 0.502, 습도 삭제처리 -> 습도 양호해짐, 0.234, 풍속 삭제처리\n",
    "# 개별변수의 VIF값\n",
    "# = 74.068, 이슬점온도 삭제처리, 6.133, 체감온도 보류\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['풍속']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdy = data.iloc[:, 0]\n",
    "pdx = data.iloc[:, 1:]\n",
    "x_train,x_test,y_train,y_test=train_test_split(pdx,pdy,train_size=0.3, random_state = 42)\n",
    "x_train_new = sm.add_constant(x_train)\n",
    "x_test_new = sm.add_constant(x_test)\n",
    "full_mod = sm.OLS(y_train,x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               avgY_moo   R-squared:                       0.484\n",
      "Model:                            OLS   Adj. R-squared:                  0.481\n",
      "Method:                 Least Squares   F-statistic:                     186.6\n",
      "Date:                Wed, 19 Feb 2020   Prob (F-statistic):          7.92e-113\n",
      "Time:                        13:50:29   Log-Likelihood:                -5493.0\n",
      "No. Observations:                 802   AIC:                         1.100e+04\n",
      "Df Residuals:                     797   BIC:                         1.102e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -3945.1456   1649.564     -2.392      0.017   -7183.148    -707.143\n",
      "현재기온          35.4094      1.824     19.413      0.000      31.829      38.990\n",
      "체감온도          -4.1565      0.607     -6.846      0.000      -5.348      -2.965\n",
      "습도             2.3408      0.442      5.300      0.000       1.474       3.208\n",
      "해면기압           4.9098      1.608      3.053      0.002       1.753       8.067\n",
      "==============================================================================\n",
      "Omnibus:                       32.572   Durbin-Watson:                   2.069\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.817\n",
      "Skew:                           0.512   Prob(JB):                     1.67e-08\n",
      "Kurtosis:                       2.852   Cond. No.                     2.08e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.08e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " Variance Inflation Factor\n",
      "현재기온 4.612\n",
      "체감온도 6.025\n",
      "습도 1.39\n",
      "해면기압 2.3\n"
     ]
    }
   ],
   "source": [
    "# 독립변수의 R제곱, P값까지 포함한 모델 요약 출력\n",
    "full_res = full_mod.fit()\n",
    "print('\\n \\n', full_res.summary())\n",
    "\n",
    "# 각 개별 변수의 VIF를 계산\n",
    "# 각 변수의 R제곱값을 계산, VIF 값으로 변환\n",
    "print('\\n Variance Inflation Factor')\n",
    "cnames = x_train.columns\n",
    "for i in np.arange(0,len(cnames)):\n",
    "    xvars = list(cnames)\n",
    "    yvars = xvars.pop(i)\n",
    "    mod = sm.OLS(x_train[yvars], sm.add_constant( x_train_new[xvars]))\n",
    "    res = mod.fit()\n",
    "    vif = 1/(1-res.rsquared)\n",
    "    print(yvars, round(vif, 3))\n",
    "    \n",
    "\n",
    "# AIS \n",
    "# = 1.099e+04 -> 1.100e+04 -> 1.100e+04\n",
    "# 수정 R제곱\n",
    "# = 0.483 -> 0.481 -> 0.481\n",
    "# 개별변수의 P값 ( P > |t|)\n",
    "# = 0.502, 습도 삭제처리 -> 습도 양호해짐, 0.234, 풍속 삭제처리 -> 전체적으로 양호\n",
    "# 개별변수의 VIF값\n",
    "# = 74.068, 이슬점온도 삭제처리 -> 6.133, 체감온도 보류 -> 6.025, 체감온도 삭제처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['체감온도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdy = data.iloc[:, 0]\n",
    "pdx = data.iloc[:, 1:]\n",
    "x_train,x_test,y_train,y_test=train_test_split(pdx,pdy,train_size=0.3, random_state = 42)\n",
    "x_train_new = sm.add_constant(x_train)\n",
    "x_test_new = sm.add_constant(x_test)\n",
    "full_mod = sm.OLS(y_train,x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               avgY_moo   R-squared:                       0.453\n",
      "Model:                            OLS   Adj. R-squared:                  0.451\n",
      "Method:                 Least Squares   F-statistic:                     220.5\n",
      "Date:                Wed, 19 Feb 2020   Prob (F-statistic):          3.56e-104\n",
      "Time:                        13:50:29   Log-Likelihood:                -5515.9\n",
      "No. Observations:                 802   AIC:                         1.104e+04\n",
      "Df Residuals:                     798   BIC:                         1.106e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -8007.3173   1582.764     -5.059      0.000   -1.11e+04   -4900.444\n",
      "현재기온          25.4321      1.128     22.548      0.000      23.218      27.646\n",
      "습도             1.5371      0.438      3.511      0.000       0.678       2.396\n",
      "해면기압           8.9602      1.538      5.826      0.000       5.941      11.979\n",
      "==============================================================================\n",
      "Omnibus:                       26.693   Durbin-Watson:                   2.090\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.681\n",
      "Skew:                           0.455   Prob(JB):                     5.91e-07\n",
      "Kurtosis:                       2.828   Cond. No.                     1.94e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.94e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " Variance Inflation Factor\n",
      "현재기온 1.668\n",
      "습도 1.291\n",
      "해면기압 1.989\n"
     ]
    }
   ],
   "source": [
    "# 독립변수의 R제곱, P값까지 포함한 모델 요약 출력\n",
    "full_res = full_mod.fit()\n",
    "print('\\n \\n', full_res.summary())\n",
    "\n",
    "# 각 개별 변수의 VIF를 계산\n",
    "# 각 변수의 R제곱값을 계산, VIF 값으로 변환\n",
    "print('\\n Variance Inflation Factor')\n",
    "cnames = x_train.columns\n",
    "for i in np.arange(0,len(cnames)):\n",
    "    xvars = list(cnames)\n",
    "    yvars = xvars.pop(i)\n",
    "    mod = sm.OLS(x_train[yvars], sm.add_constant( x_train_new[xvars]))\n",
    "    res = mod.fit()\n",
    "    vif = 1/(1-res.rsquared)\n",
    "    print(yvars, round(vif, 3))\n",
    "    \n",
    "\n",
    "# AIS \n",
    "# = 1.099e+04 -> 1.100e+04 -> 1.100e+04 -> 1.104e+04\n",
    "# 수정 R제곱\n",
    "# = 0.483 -> 0.481 -> 0.481 -> 0.451\n",
    "# 개별변수의 P값 ( P > |t|)\n",
    "# = 0.502, 습도 삭제처리 -> 습도 양호해짐, 0.234, 풍속 삭제처리 -> 전체적으로 양호\n",
    "# 개별변수의 VIF값\n",
    "# = 74.068, 이슬점온도 삭제처리 -> 6.133, 체감온도 보류 -> 6.025, 체감온도 삭제처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgY_moo</th>\n",
       "      <th>현재기온</th>\n",
       "      <th>습도</th>\n",
       "      <th>해면기압</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1334</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1007.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1314</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1019.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1287</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1275</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1022.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1255</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1020.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2671</td>\n",
       "      <td>1618</td>\n",
       "      <td>10.9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1025.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2672</td>\n",
       "      <td>1596</td>\n",
       "      <td>6.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1012.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2673</td>\n",
       "      <td>1582</td>\n",
       "      <td>8.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1022.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2674</td>\n",
       "      <td>1480</td>\n",
       "      <td>13.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1019.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>1473</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1031.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      avgY_moo  현재기온    습도    해면기압\n",
       "0         1334  -6.0  90.0  1007.7\n",
       "1         1314 -11.7  69.0  1019.2\n",
       "2         1287 -10.6  56.0  1021.5\n",
       "3         1275  -6.1  54.0  1022.8\n",
       "4         1255  -3.8  54.0  1020.1\n",
       "...        ...   ...   ...     ...\n",
       "2671      1618  10.9  45.0  1025.4\n",
       "2672      1596   6.1  68.0  1012.9\n",
       "2673      1582   8.1  22.0  1022.1\n",
       "2674      1480  13.3  68.0  1019.7\n",
       "2675      1473   2.5  20.0  1031.1\n",
       "\n",
       "[2676 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 본격적으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 릿지, 라소 회귀\n",
    "- 튜닝 매개변수(λ)로 계수를 정규화하기 위해서 변수에 패널티를 적용한다.\n",
    "- λ=0, 패널티 영향 X  \n",
    "  λ=∞로 갈수록 계수들은 0이 된다.\n",
    "  \n",
    "#### 릿지\n",
    "- 모든 예측변수를 중요도에 따라 가중치만 축소, 0값을 부여하지 않음  \n",
    "  => 불필요한 변수가 제거되지 않는다.\n",
    "\n",
    "#### 라소\n",
    "- 0까지 할당하기 때문에  \n",
    "  => 불필요한 변수를 제거해준다.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ridge Regression: Best Parameters \n",
      "\n",
      "alpha :  0.0001\n",
      "0.4461401349288595\n",
      "0.44405995058749076\n",
      " =====================\n",
      " === change record ===\n",
      "Lambda :  0.0001 Train_Acc :  0.44614 \n",
      "Test_Acc :  0.44406\n",
      " =====================\n",
      "alpha :  0.001\n",
      "0.4461386545542968\n",
      "0.4441241338358157\n",
      "alpha :  0.01\n",
      "0.4459978526711784\n",
      "0.4446255920281603\n",
      "alpha :  0.1\n",
      "0.43688403948393106\n",
      "0.44068197432382794\n",
      "alpha :  0.5\n",
      "0.37374263412428765\n",
      "0.38656739168281984\n",
      "alpha :  1.0\n",
      "0.31649206918883366\n",
      "0.3311471400858558\n",
      "alpha :  5.0\n",
      "0.14749232962153747\n",
      "0.15646465134840237\n",
      "alpha :  10.0\n",
      "0.0887742732489265\n",
      "0.09434032347354404\n"
     ]
    }
   ],
   "source": [
    "# normalize=False\n",
    "#  === change record ===\n",
    "# Lambda :  0.0001 Train_Acc :  0.47022 \n",
    "# Test_Acc :  0.5417\n",
    "#  =====================\n",
    "# normalize=False\n",
    "#  === change record ===\n",
    "# Lambda :  0.0001 Train_Acc :  0.46259 \n",
    "# Test_Acc :  0.56623\n",
    "#  =====================\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# y, 타겟 / X, 트레인 데이터\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, shuffle=True)\n",
    "\n",
    "alphas = [1e-4, 1e-3, 1e-2, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "\n",
    "initacc = 0\n",
    "\n",
    "print('\\n Ridge Regression: Best Parameters \\n')\n",
    "for alph in alphas:\n",
    "    ridge_reg = Ridge(alpha=alph, normalize=True)\n",
    "    ridge_reg.fit(X_train, y_train)\n",
    "    y_pred = ridge_reg.predict(X_test)\n",
    "    print(\"alpha : \", alph)\n",
    "    print(ridge_reg.score(X_train, y_train))\n",
    "    print(ridge_reg.score(X_test, y_test))\n",
    "    \n",
    "#     tr_rsqrd = ridge_reg.score(x_train, y_train)\n",
    "#     ts_rsqrd = ridge_reg.score(x_test, y_test)\n",
    "    if ridge_reg.score(X_test, y_test) - initacc > 0.001:\n",
    "        print( \" =====================\")\n",
    "        print( \" === change record ===\")\n",
    "        print(\"Lambda : \", alph, \"Train_Acc : \",\n",
    "              round(ridge_reg.score(X_train, y_train),5), \"\\nTest_Acc : \", \n",
    "              round(ridge_reg.score(X_test, y_test),5))\n",
    "        initacc = ridge_reg.score(X_test, y_test)\n",
    "        print( \" =====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lasso Regression: Best Parameters \n",
      "\n",
      "alpha :  0.0001\n",
      "0.45006322287858047\n",
      "0.43400916950034335\n",
      " =====================\n",
      " === change record ===\n",
      "Lambda :  0.0001 \n",
      "Train_Acc :  0.45006 \n",
      "Test_Acc :  0.43401\n",
      " =====================\n",
      "alpha :  0.001\n",
      "0.4500632228776209\n",
      "0.4340091374499306\n",
      "alpha :  0.01\n",
      "0.45006322278163124\n",
      "0.43400881681900916\n",
      "alpha :  0.1\n",
      "0.4500632131784914\n",
      "0.4340056006099542\n",
      "alpha :  0.5\n",
      "0.4500629803937164\n",
      "0.43399109192224655\n",
      "alpha :  1.0\n",
      "0.45006225243669606\n",
      "0.43397246085054364\n",
      "alpha :  5.0\n",
      "0.4500389671941856\n",
      "0.4338037099067538\n",
      "alpha :  10.0\n",
      "0.4499661659981537\n",
      "0.43354342865627005\n"
     ]
    }
   ],
   "source": [
    "# normalize=True\n",
    "#  === change record ===\n",
    "# Lambda :  0.0001 \n",
    "# Train_Acc :  0.4805 \n",
    "# Test_Acc :  0.52211\n",
    "#  =====================\n",
    "# normalize=False\n",
    "#  === change record ===\n",
    "# Lambda :  0.0001 \n",
    "# Train_Acc :  0.48102 \n",
    "# Test_Acc :  0.51825\n",
    "#  =====================\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# y, 타겟 / X, 트레인 데이터\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, shuffle=True)\n",
    "\n",
    "alphas = [1e-4, 1e-3, 1e-2, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "\n",
    "initacc = 0\n",
    "\n",
    "print('\\n Lasso Regression: Best Parameters \\n')\n",
    "for alph in alphas:\n",
    "    lasso_reg = Lasso(alpha=alph)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "    y_pred = lasso_reg.predict(X_test)\n",
    "    print(\"alpha : \", alph)\n",
    "    print(lasso_reg.score(X_train, y_train))\n",
    "    print(lasso_reg.score(X_test, y_test))\n",
    "\n",
    "    if lasso_reg.score(X_test, y_test) - initacc > 0.001:\n",
    "        print( \" =====================\")\n",
    "        print( \" === change record ===\")\n",
    "        print(\"Lambda : \", alph, \"\\nTrain_Acc : \",\n",
    "              round(lasso_reg.score(X_train, y_train),5), \"\\nTest_Acc : \", \n",
    "              round(lasso_reg.score(X_test, y_test),5))\n",
    "        initacc = lasso_reg.score(X_test, y_test)\n",
    "        print( \" =====================\")\n",
    "        \n",
    "# 0.48까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ElasticNet Regression: Best Parameters \n",
      "\n",
      "l1_ratio :  0.1\n",
      "0.4592105283150865\n",
      "0.4142506832052752\n",
      " =====================\n",
      " === change record ===\n",
      "l1Ratios :  0.1 \n",
      "Train_Acc :  0.45921 \n",
      "Test_Acc :  0.41425\n",
      " =====================\n",
      "l1_ratio :  0.2\n",
      "0.4592105283154948\n",
      "0.4142506659088932\n",
      "l1_ratio :  0.3\n",
      "0.4592105283158582\n",
      "0.4142506486162609\n",
      "l1_ratio :  0.4\n",
      "0.45921052831617715\n",
      "0.4142506313169845\n",
      "l1_ratio :  0.5\n",
      "0.45921052831645126\n",
      "0.4142506140176482\n",
      "l1_ratio :  0.6\n",
      "0.45921052831668036\n",
      "0.4142505967182525\n",
      "l1_ratio :  0.7\n",
      "0.4592105283168649\n",
      "0.4142505794187971\n",
      "l1_ratio :  0.8\n",
      "0.45921052831700476\n",
      "0.41425056213490424\n",
      "l1_ratio :  0.9\n",
      "0.4592105283170996\n",
      "0.41425054483533047\n"
     ]
    }
   ],
   "source": [
    "# normalize=True\n",
    "#  === change record ===\n",
    "# l1Ratios :  10.0 \n",
    "# Train_Acc :  0.47181 \n",
    "# Test_Acc :  0.53052\n",
    "#  =====================\n",
    "# normalize=False\n",
    "#  === change record ===\n",
    "# l1Ratios :  0.1 \n",
    "# Train_Acc :  0.47517 \n",
    "# Test_Acc :  0.52925\n",
    "#  =====================\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# y, 타겟 / X, 트레인 데이터\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, shuffle=True)\n",
    "\n",
    "alphas = [1e-4, 1e-3, 1e-2, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "l1Ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "initacc = 0\n",
    "\n",
    "print('\\n ElasticNet Regression: Best Parameters \\n')\n",
    "for l1Ratio in l1Ratios:\n",
    "    el_lasso_reg = ElasticNet(l1_ratio=l1Ratio , alpha=0.0001, normalize=False)\n",
    "    el_lasso_reg.fit(X_train, y_train)\n",
    "    y_pred = el_lasso_reg.predict(X_test)\n",
    "    print(\"l1_ratio : \", l1Ratio)\n",
    "    print(el_lasso_reg.score(X_train, y_train))\n",
    "    print(el_lasso_reg.score(X_test, y_test))\n",
    "\n",
    "    if el_lasso_reg.score(X_test, y_test) - initacc > 0.01:\n",
    "        print( \" =====================\")\n",
    "        print( \" === change record ===\")\n",
    "        print(\"l1Ratios : \", l1Ratio, \"\\nTrain_Acc : \",\n",
    "              round(el_lasso_reg.score(X_train, y_train),5), \"\\nTest_Acc : \", \n",
    "              round(el_lasso_reg.score(X_test, y_test),5))\n",
    "        initacc = el_lasso_reg.score(X_test, y_test)\n",
    "        print( \" =====================\")\n",
    "\n",
    "# for alph in alphas:\n",
    "#     el_lasso_reg = ElasticNet(l1_ratio= , alpha=alph, normalize=True)\n",
    "#     el_lasso_reg.fit(X_train, y_train)\n",
    "#     y_pred = el_lasso_reg.predict(X_test)\n",
    "#     print(\"alpha : \", alph)\n",
    "#     print(el_lasso_reg.score(X_train, y_train))\n",
    "#     print(el_lasso_reg.score(X_test, y_test))\n",
    "\n",
    "#     if el_lasso_reg.score(X_test, y_test) - initacc > 0.001:\n",
    "#         print( \" =====================\")\n",
    "#         print( \" === change record ===\")\n",
    "#         print(\"Lambda : \", alph, \"\\nTrain_Acc : \",\n",
    "#               round(el_lasso_reg.score(X_train, y_train),5), \"\\nTest_Acc : \", \n",
    "#               round(el_lasso_reg.score(X_test, y_test),5))\n",
    "#         initacc = el_lasso_reg.score(X_test, y_test)\n",
    "#         print( \" =====================\")\n",
    "\n",
    "# 0.46 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVR Regression: Best Parameters \n",
      "\n",
      "C :  1.0\n",
      "0.006564538870257874\n",
      "1.5718145256360394e-05\n",
      "C :  10.0\n",
      "0.09302388069627411\n",
      "0.03777651895691536\n",
      " =====================\n",
      " === change record ===\n",
      "Lambda :  10.0 \n",
      "Train_Acc :  0.09302 \n",
      "Test_Acc :  0.03778\n",
      " =====================\n",
      "C :  100.0\n",
      "0.5761106457843335\n",
      "0.23412781733415833\n",
      " =====================\n",
      " === change record ===\n",
      "Lambda :  100.0 \n",
      "Train_Acc :  0.57611 \n",
      "Test_Acc :  0.23413\n",
      " =====================\n",
      "C :  500.0\n",
      "0.9354059918759348\n",
      "0.32785381600603414\n",
      " =====================\n",
      " === change record ===\n",
      "Lambda :  500.0 \n",
      "Train_Acc :  0.93541 \n",
      "Test_Acc :  0.32785\n",
      " =====================\n",
      "C :  1000.0\n",
      "0.9735257430116123\n",
      "0.3190320724124581\n"
     ]
    }
   ],
   "source": [
    "# C parameter\n",
    "#  === change record ===\n",
    "# Lambda :  500.0 \n",
    "# Train_Acc :  0.93479 \n",
    "# Test_Acc :  0.38305\n",
    "#  =====================\n",
    "\n",
    "\n",
    "# kernel = ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "# default : rbf\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# y, 타겟 / X, 트레인 데이터\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, shuffle=True)\n",
    "\n",
    "Cs = [1.0, 10.0, 100.0, 500.0, 1000.0]\n",
    "\n",
    "initacc = 0\n",
    "\n",
    "print('\\n SVR Regression: Best Parameters \\n')\n",
    "for Cone in Cs:\n",
    "    SVR_reg = SVR(C=Cone)\n",
    "    SVR_reg.fit(X_train, y_train)\n",
    "    y_pred = SVR_reg.predict(X_test)\n",
    "    print(\"C : \", Cone)\n",
    "    print(SVR_reg.score(X_train, y_train))\n",
    "    print(SVR_reg.score(X_test, y_test))\n",
    "\n",
    "    if SVR_reg.score(X_test, y_test) - initacc > 0.001:\n",
    "        print( \" =====================\")\n",
    "        print( \" === change record ===\")\n",
    "        print(\"Lambda : \", Cone, \"\\nTrain_Acc : \",\n",
    "              round(SVR_reg.score(X_train, y_train),5), \"\\nTest_Acc : \", \n",
    "              round(SVR_reg.score(X_test, y_test),5))\n",
    "        initacc = SVR_reg.score(X_test, y_test)\n",
    "        print( \" =====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 70.08645009994507\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C parameter\n",
    "#  === change record ===\n",
    "# Lambda :  500.0 \n",
    "# Train_Acc :  0.93479 \n",
    "# Test_Acc :  0.38305\n",
    "#  =====================\n",
    "\n",
    "\n",
    "# kernel = ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "# default : rbf\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# y, 타겟 / X, 트레인 데이터\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, shuffle=True)\n",
    "\n",
    "# Cs = [100.0, 200.0, 300.0, 400.0, 500.0]\n",
    "# initacc = 0\n",
    "\n",
    "# print('\\n SVR Regression: Best Parameters \\n')\n",
    "# for Cone in Cs:\n",
    "#     SVR_reg = SVR(C=Cone)\n",
    "#     SVR_reg.fit(X_train, y_train)\n",
    "#     y_pred = SVR_reg.predict(X_test)\n",
    "#     print(\"C : \", Cone)\n",
    "#     print(SVR_reg.score(X_train, y_train))\n",
    "#     print(SVR_reg.score(X_test, y_test))\n",
    "\n",
    "#     if SVR_reg.score(X_test, y_test) - initacc > 0.001:\n",
    "#         print( \" =====================\")\n",
    "#         print( \" === change record ===\")\n",
    "#         print(\"Lambda : \", Cone, \"\\nTrain_Acc : \",\n",
    "#               round(SVR_reg.score(X_train, y_train),5), \"\\nTest_Acc : \", \n",
    "#               round(SVR_reg.score(X_test, y_test),5))\n",
    "#         initacc = SVR_reg.score(X_test, y_test)\n",
    "#         print( \" =====================\")\n",
    "        \n",
    "C_limit = 300.0\n",
    "C_one = 100.0\n",
    "\n",
    "C_li = list()\n",
    "trainAcc_li = list()\n",
    "testAcc_li = list()\n",
    "\n",
    "while C_one < C_limit:\n",
    "    SVR_reg = SVR(C=C_one)\n",
    "    SVR_reg.fit(X_train, y_train)\n",
    "    y_pred = SVR_reg.predict(X_test)\n",
    "    C_li.append(C_one)\n",
    "    trainAcc_li.append(SVR_reg.score(X_train, y_train))\n",
    "    testAcc_li.append(SVR_reg.score(X_test, y_test))\n",
    "    C_one += 1.0\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(trainAcc_li)\n",
    "ax.plot(testAcc_li)\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondacb974de5d481480ca67f41f19bdbb3fc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
